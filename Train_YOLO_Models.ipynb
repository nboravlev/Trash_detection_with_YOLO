{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sUfcA8ZgR2t"
      },
      "source": [
        "# Train YOLO Models in Google Colab\n",
        "**Author:** Николай Боравлев\n",
        "\n",
        "**Last updated:**  21/05/2025\n",
        "\n",
        "**GitHub:** [Обучение модели YOLO и применение для детекции объектов](https://github.com/nboravlev/Trash_detection_with_YOLO)\n",
        "\n",
        "# Introduction\n",
        "\n",
        "Этот ноутбук использует фреймворк [Ultralytics](https://docs.ultralytics.com/) для обучения YOLO11, YOLOv8, или YOLOv5 на пользовательском наборе данных. В конце этого ноутбука мы получим готовую модель YOLO, специально обученную для решения задачи детекции на нашем собственном наборе данных, которую можно использовать локально на ПК, телефоне или на внешних устройствах типа Raspberry Pi.\n",
        "\n",
        "\n",
        "\n",
        "### Working in Colab\n",
        "Colab предоставляет виртуальную машину, доступную из браузера. В ней уже заранее настроена фаловая система, Python окружение, и самое главное - бесплатные видеокарты для обучения. Скачаем в нашу среду дополнительно PyTorch and Ultralytics, необходимые для обучения, и приступим.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Verify NVIDIA GPU Availability**\n",
        "\n",
        "Убедимся, что ноутбук подключен к видеокарте. Для этого необходимо выбрать в меню \"Среда выполнения\" -> \"Сменить среду выполнения\" и в разделе \"Аппаратный ускоритель\" выбрать \"Графический процессор\". Что убедиться, что подключение установлено, выполним команду:"
      ],
      "metadata": {
        "id": "3NW7LLv_QPOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "cfaWho47RGDf",
        "outputId": "3b38f765-aaf2-428c-f3fc-2fc7ce65a2bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue May 13 19:05:52 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eDhuvzDfIFS"
      },
      "source": [
        "# 2.&nbsp;Upload Image Dataset and Prepare Training Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZW_0c110fOiz"
      },
      "source": [
        "В этом разделе мы готовим данные для обучения"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Upload images\n",
        "\n",
        "Загрузка изображений"
      ],
      "metadata": {
        "id": "FwKAqFIQSBpn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Я скачаю свои данные, которые я предварительно разметил вручную из репозитория GitHub. Архив с данными будет лежать в корневой папке моей текущей работчей среды."
      ],
      "metadata": {
        "id": "ZPZEM27IOh79"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZQXLBvL5grDl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f06bb5c-5913-40f7-ec1a-eeeecb334e06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-24 10:52:40--  https://github.com/nboravlev/Trash_detection_with_YOLO/raw/main/project_yolo_with_foto_05-13.zip\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/nboravlev/Trash_detection_with_YOLO/main/project_yolo_with_foto_05-13.zip [following]\n",
            "--2025-05-24 10:52:41--  https://raw.githubusercontent.com/nboravlev/Trash_detection_with_YOLO/main/project_yolo_with_foto_05-13.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11034622 (11M) [application/zip]\n",
            "Saving to: ‘/content/data.zip’\n",
            "\n",
            "/content/data.zip   100%[===================>]  10.52M  51.0MB/s    in 0.2s    \n",
            "\n",
            "2025-05-24 10:52:41 (51.0 MB/s) - ‘/content/data.zip’ saved [11034622/11034622]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O /content/data.zip https://github.com/nboravlev/Trash_detection_with_YOLO/raw/main/project_yolo_with_foto_05-13.zip # Trash dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Split images into train and validation folders"
      ],
      "metadata": {
        "id": "m7Iz9eBzW5zm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Чтобы разложить данные по папкам для обучения и валидации, необходимо сперва извлечь их из архива. Проверим, что наш архив `data.zip` корректно загружен и теперь лежит в корневой папке в нашей рабочей среде. Далее распакуем архив, выполнив следующий код:"
      ],
      "metadata": {
        "id": "58JuFGc2PatU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "z8O6z-wVcPEF"
      },
      "outputs": [],
      "source": [
        "# Unzip images to a custom data folder\n",
        "!unzip -q /content/data.zip -d /content/custom_data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ultralytics для обучения модели требуется определенная структура данных: корневая папка называется “data”. Внутри еще две папки:\n",
        "\n",
        "*   **Train**: В этой папке лежат данные для обучения модели. В течение кажждой эпохи обучения каждое изображение отправляется в модель, и в процессе обучения модель корректирует свои веса с учетом это йинформации.\n",
        "\n",
        "\n",
        "*   **Validation**: Эти данные не участвуют в обучении, в конце каждой эпохи модель использует эти данные для оценки свое работы.\n",
        "\n",
        "*   **Test**: Данные для оценки качества работы после обучения. В процессе обучения модель их вообще не будет видеть.\n",
        "\n",
        "Внутри этих папок данные лежат с папках “images” и “labels”, в которых .содержатся соответственно изображения и аннотации."
      ],
      "metadata": {
        "id": "eoPjqW6AYebn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Скрит для разделения данных лежит в моем репозитории, сперва необходимо скачать в рабочую среду, затем вызвать, передав в качестве аргументов путь к данным и пару служебных параметров `--train_prc` - доля данных на обучение и `--test_prc`- доля данных на тест. Оставшаяся часть пойдет на валидацию.\n",
        "Скрипт выполняет сплит и раскладывает данные по папкам в соответсвии со структурой, которую требует Ultralytics для своих моделей."
      ],
      "metadata": {
        "id": "f2ohNAhWj41n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O /content/train_val_split.py https://github.com/nboravlev/Trash_detection_with_YOLO/raw/main/Utils/train_val_split.py\n",
        "\n",
        "# TO DO: Improve robustness of train_val_split.py script so it can handle nested data folders, etc\n",
        "!python train_val_split.py --datapath=\"/content/custom_data\" --train_pct=.85 --test_pct=.05"
      ],
      "metadata": {
        "id": "8X62eFTugosf",
        "outputId": "5e875e21-20c8-4440-8c85-313f46a3b7a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-24 12:35:07--  https://github.com/nboravlev/Trash_detection_with_YOLO/raw/main/Utils/train_val_split.py\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/nboravlev/Trash_detection_with_YOLO/main/Utils/train_val_split.py [following]\n",
            "--2025-05-24 12:35:07--  https://raw.githubusercontent.com/nboravlev/Trash_detection_with_YOLO/main/Utils/train_val_split.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3669 (3.6K) [text/plain]\n",
            "Saving to: ‘/content/train_val_split.py’\n",
            "\n",
            "/content/train_val_ 100%[===================>]   3.58K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-05-24 12:35:08 (43.0 MB/s) - ‘/content/train_val_split.py’ saved [3669/3669]\n",
            "\n",
            "Created folder at /content/data/train/images.\n",
            "Created folder at /content/data/train/labels.\n",
            "Created folder at /content/data/validation/images.\n",
            "Created folder at /content/data/validation/labels.\n",
            "Created folder at /content/data/test/images.\n",
            "Created folder at /content/data/test/labels.\n",
            "Number of image files: 214\n",
            "Number of annotation files: 214\n",
            "Images moving to train: 181\n",
            "Images moving to test: 10\n",
            "Images moving to validation: 23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.3 Look at the Data"
      ],
      "metadata": {
        "id": "TYN3ocmhS82m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def count_classes(labels_folder):\n",
        "    class_counts = {}\n",
        "\n",
        "    # Проход по всем файлам в папке с метками\n",
        "    for filename in os.listdir(labels_folder):\n",
        "        if filename.endswith('.txt'):\n",
        "            file_path = os.path.join(labels_folder, filename)\n",
        "\n",
        "            with open(file_path, 'r') as file:\n",
        "                for line in file:\n",
        "                    line = line.strip()\n",
        "                    if not line:\n",
        "                        continue  # Пропускаем пустые строки\n",
        "\n",
        "                    parts = line.split()\n",
        "                    if not parts:\n",
        "                        continue  # Пропускаем строки без данных\n",
        "\n",
        "                    try:\n",
        "                        class_id = int(parts[0])\n",
        "                        class_counts[class_id] = class_counts.get(class_id, 0) + 1\n",
        "                    except (ValueError, IndexError):\n",
        "                        continue  # Пропускаем некорректные строки\n",
        "\n",
        "    # Сортируем классы по возрастанию ID\n",
        "    sorted_classes = sorted(class_counts.items(), key=lambda x: x[0])\n",
        "\n",
        "    # Выводим результаты\n",
        "    print(\"Количество объектов по классам:\")\n",
        "    for class_id, count in sorted_classes:\n",
        "        print(f\"Класс {class_id}: {count} объектов\")\n",
        "    print(f\"Всего классов: {len(sorted_classes)}\")\n",
        "    print(f\"Всего объектов: {sum(class_counts.values())}\")\n",
        "\n",
        "# Укажите путь к вашей папке с метками\n",
        "labels_dir = '/content/custom_data/labels'\n",
        "count_classes(labels_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4llIckFXTB9j",
        "outputId": "0f1b75ae-1b9d-4d2d-adf3-691da883d08a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество объектов по классам:\n",
            "Класс 0: 454 объектов\n",
            "Класс 1: 220 объектов\n",
            "Класс 2: 268 объектов\n",
            "Всего классов: 3\n",
            "Всего объектов: 942\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.&nbsp;Install Ultralytics\n",
        "\n",
        "Далее требуется скачать и установить в рабочую среду фреймфорк для обучения и тестирования модели - Ultralytics"
      ],
      "metadata": {
        "id": "B2L2qGCJzwY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "EMEDk5byzxY5",
        "outputId": "8863668c-6a2d-40ef-c15b-5e001648e096",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.134-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.4.26)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.134-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuZoMkSFN9XG"
      },
      "source": [
        "# 4.&nbsp;Configure Training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ultralytics для работы требует файл конфигурации YAML. В этом файле прописываются пути к данным и перечисляются классы объектов.\n",
        " [Здесь](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/coco128.yaml) можно ознакомиться с примером такого файла.\n",
        "\n",
        "Код внизу автоматически генерирует `data.yaml` файл. необходимо удостовериться, что карта классов лежит по адресу `custom_data/classes.txt`. Если данные готовились с помощью Label Studio, то такой файлл уже существует. Иначе придется создать файл `classes.txt` самостоятельно в текстовом редакторе и загрузить в Google Colab ([пример](https://github.com/nboravlev/Trash_detection_with_YOLO/blob/main/Docs/classes.txt) файла `classes.txt`)."
      ],
      "metadata": {
        "id": "0c5Kdh0GmQHS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Python function to automatically create data.yaml config file\n",
        "# 1. Reads \"classes.txt\" file to get list of class names\n",
        "# 2. Creates data dictionary with correct paths to folders, number of classes, and names of classes\n",
        "# 3. Writes data in YAML format to data.yaml\n",
        "\n",
        "import yaml\n",
        "import os\n",
        "\n",
        "def create_data_yaml(path_to_classes_txt, path_to_data_yaml):\n",
        "\n",
        "  # Read class.txt to get class names\n",
        "  if not os.path.exists(path_to_classes_txt):\n",
        "    print(f'classes.txt file not found! Please create a classes.txt labelmap and move it to {path_to_classes_txt}')\n",
        "    return\n",
        "  with open(path_to_classes_txt, 'r') as f:\n",
        "    classes = []\n",
        "    for line in f.readlines():\n",
        "      if len(line.strip()) == 0: continue\n",
        "      classes.append(line.strip())\n",
        "  number_of_classes = len(classes)\n",
        "\n",
        "  # Create data dictionary\n",
        "  data = {\n",
        "      'path': '/content/data',\n",
        "      'train': 'train/images',\n",
        "      'val': 'validation/images',\n",
        "      'test': 'test/images',\n",
        "      'nc': number_of_classes,\n",
        "      'names': classes\n",
        "  }\n",
        "\n",
        "  # Write data to YAML file\n",
        "  with open(path_to_data_yaml, 'w') as f:\n",
        "    yaml.dump(data, f, sort_keys=False)\n",
        "  print(f'Created config file at {path_to_data_yaml}')\n",
        "\n",
        "  return\n",
        "\n",
        "# Define path to classes.txt and run function\n",
        "path_to_classes_txt = '/content/custom_data/classes.txt'\n",
        "path_to_data_yaml = '/content/data.yaml'\n",
        "\n",
        "create_data_yaml(path_to_classes_txt, path_to_data_yaml)\n",
        "\n",
        "print('\\nFile contents:\\n')\n",
        "!cat /content/data.yaml"
      ],
      "metadata": {
        "id": "4letvP7X12ji",
        "outputId": "857a1796-604f-4684-eaaa-52976c1d40e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created config file at /content/data.yaml\n",
            "\n",
            "File contents:\n",
            "\n",
            "path: /content/data\n",
            "train: train/images\n",
            "val: validation/images\n",
            "test: test/images\n",
            "nc: 3\n",
            "names:\n",
            "- bin\n",
            "- tires\n",
            "- trash\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5.1 Training Parameters\n",
        "Данные готовы для обучения, размечены, корректно расположены в тех местах, где их ожидает найти наш скрипт, вспомогательные документы сформированы и загружены в рабочую среду, модель готова обучаться! Перед началом обучения рекумендуется посетить сайт [Ultralytics](https://docs.ultralytics.com/ru/tasks/detect/#models) чтобы ознакомиться с аргументами, которые принимает скрипт запуска обучения. Ниже подробнее остановлюсь на некоторых из них.\n",
        "\n",
        "**Model architecture & size (`model`):**\n",
        "\n",
        "Мы всегда ищем баланс между размером модели, стоимостью обучения, качеством и скоростью работы. Модель YOLO11 существует в нескольких размерах yolo11n.pt, yolo11s.pt, yolo11m.pt, yolo11l.pt, and yolo11xl.pt.\n",
        "\n",
        "![YOLO11](https://github.com/nboravlev/Trash_detection_with_YOLO/raw/main/Docs/YOLO11.PNG)\n",
        "\n",
        "Логично, что чем больше модель, тем выше качество и ниже скорость работы. Анализируя сравнительную таблицу можно сказать, что yolo11m это довольно хороший выбор для начала.\n",
        "\n",
        "**Number of epochs (`epochs`)**\n",
        "\n",
        "\"Эпоха\" в машинном обучении это один проход модели по всем обучающим данным. От выбора количества эпох зависит продолжительность обучения. На выбор количества эпох влияет, например, количество данных. Если формализовать, то можно сказать, что если количество обучающих изображений меньше 200, то следует брать 60 эпох, если больше, то 40.  После обучения на графике можно будет увидеть по динамике значения **`loss`**, какое количество было бы оптимальным. В любом случае, алгоритм сохраняет версию модели с наилучшими метриками качества.\n",
        "\n",
        "**Resolution (`imgsz`)**\n",
        "\n",
        "Этот аргумент отвечает за разрешение изображения, которое передается в модель. Понятно, что от этого параметра напрямую зависит скорость и качество. В целом, стандартом для YOLO является разрешение 640x640, но если заранее известно, что модель будет получать изображения невысокого качества или скорость обучения является приоритетом. можно уменьшить разрешение до, например, 480px"
      ],
      "metadata": {
        "id": "KzuN_WSbcR9j"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myP80_bnTNMi"
      },
      "source": [
        "# 5.&nbsp;Train Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для инициализации обучения достаточно выполнить блок кода внизу. При необходимости можно подставить свои значения в аргумент `model`, `epochs` или `imgsz`."
      ],
      "metadata": {
        "id": "nQi_hXnUVPr-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bbpob1gTPlo",
        "collapsed": true,
        "outputId": "68d1d168-4845-4f63-8fe3-12ff20a3cf8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: yolo: command not found\n"
          ]
        }
      ],
      "source": [
        "!yolo detect train data=/content/data.yaml model=yolo11l.pt epochs=60 imgsz=640"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Алгоритм обучения парсит изображения из дерикторий \\training и \\validation и запускает обучение. В конце каждой эпохи алгоритм проходит по данным для валидации и фиксирует метрики mAP, precision, recall. В норме показатель mAP должен возрастать каждую новую эпоху. Цикл обучения повторяется столько раз, сколько указано в аргументе `epochs`.\n",
        "\n",
        "> **NOTE:** Важно не прерывать цикл обучения. В конце процесса обучения выполнятся технический скрипт-оптимизатор, который оптимизирует размер модели, удаляя ненужные слои и различные артефакты, ненужные для инференса.\n",
        "\n",
        "Веса модели, которая демонстрирует наилучшие метрики качества, сохраняются в директории `content/runs/detect/train/weights/best.pt`. Дополнительная информация об обучении сохраняется в папку `content/runs/detect/train`. В том числе файл `results.png` с динамикой, как меняется loss, precision, recall, mAP от эпохи к эпохе."
      ],
      "metadata": {
        "id": "vv0EYWJ5V6mC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vo8BJRXeg0Ap"
      },
      "source": [
        "#6.&nbsp;Test Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Чтобы визуально проверить результат, дадим модели тестовые изображения, которые она не видела на обучении, и посмотрим на результаты предсказания!\n",
        "Скрипт берет все изображения из папки /test/images, выполняет предсказание и сохраняет картинку с результатом (bbox и класс) в папку `runs/detect/predict. Результат мы потом визуализируем."
      ],
      "metadata": {
        "id": "BX3PTrEPacGY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PooP5Vjsg2Jn",
        "outputId": "a96e9f64-9f3b-45c1-ac6b-55e4eb8368c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.133 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11l summary (fused): 190 layers, 25,281,625 parameters, 0 gradients, 86.6 GFLOPs\n",
            "\n",
            "image 1/10 /content/data/test/30d66471-326f-434b-9807-8db96ac5429e.jpg: 640x320 1 bin, 103.0ms\n",
            "image 2/10 /content/data/test/358ba6d3-1470-4afc-ae42-a7db4d26d83d.jpg: 640x320 (no detections), 29.2ms\n",
            "image 3/10 /content/data/test/IMG_20250505_122812.jpg: 640x480 4 bins, 84.9ms\n",
            "image 4/10 /content/data/test/IMG_20250506_095157.jpg: 640x480 2 bins, 3 tiress, 36.3ms\n",
            "image 5/10 /content/data/test/IMG_20250510_155257.jpg: 640x480 3 bins, 2 trashs, 35.8ms\n",
            "image 6/10 /content/data/test/IMG_20250511_191241.jpg: 640x480 1 bin, 3 trashs, 35.8ms\n",
            "image 7/10 /content/data/test/IMG_20250512_112119.jpg: 640x480 2 bins, 1 trash, 35.9ms\n",
            "image 8/10 /content/data/test/IMG_20250512_113545.jpg: 640x480 4 bins, 6 tiress, 35.9ms\n",
            "image 9/10 /content/data/test/IMG_20250513_194755.jpg: 640x480 1 bin, 4 tiress, 2 trashs, 35.8ms\n",
            "image 10/10 /content/data/test/IMG_20250513_194813.jpg: 640x480 1 bin, 3 tiress, 3 trashs, 35.9ms\n",
            "Speed: 3.9ms preprocess, 46.9ms inference, 21.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/predict\n"
          ]
        }
      ],
      "source": [
        "!yolo detect predict model=runs/detect/train/weights/best.pt source=/content/data/test/images save=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEEObQqoiGrs"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "from IPython.display import Image, display\n",
        "for image_path in glob.glob(f'/content/runs/detect/predict/*.jpg')[:10]:\n",
        "  display(Image(filename=image_path, height=400))\n",
        "  print('\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "# Получаем список путей к изображениям\n",
        "image_paths = glob.glob('/content/runs/detect/predict/*.jpg')#[:10] если хотим вывести первые Х файлов\n",
        "\n",
        "# Настройки отображения\n",
        "images_per_row = 4\n",
        "total_images = len(image_paths)\n",
        "rows = (total_images // images_per_row) + (1 if total_images % images_per_row > 0 else 0)\n",
        "\n",
        "# Рисуем\n",
        "fig, axes = plt.subplots(rows, images_per_row, figsize=(15, rows * 4))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for ax, image_path in zip(axes, image_paths):\n",
        "    img = plt.imread(image_path)\n",
        "    ax.imshow(img)\n",
        "    ax.axis('off')\n",
        "\n",
        "# Скрываем пустые subplot'ы\n",
        "for ax in axes[total_images:]:\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sWMu16MG0WO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модель обводит `bbox` вокруг каждого интересующего нас объекта. Если обводит некорректно, то вот короткий список вещей, на которые следует обратить внимание:\n",
        "\n",
        "\n",
        "1. В первую очередь это конечно качество данных: ошибки и всякого рода противоречия в разметке. Воообще качество данных это самая чуствительная и важная часть. `Что положишь в модель, то и получишь`\n",
        "2. Увеличить количество эпох. Опять же, смотря по динамике loss: если loss вышел на плато, едва ли это поможет.\n",
        "3. Взять модель побольше (e.g. `yolo11l.pt`).\n",
        "4. Добавить примеров в обучающий датасет. Хорошее [видео](https://www.youtube.com/watch?v=v0ssiOY6cfg) о том, как самому выполнить разметку.\n",
        "\n",
        "Можно также запустить модель на других данных: изображениях или видео. Для этого необходимо загрузить данные в текущую рабочую среду и выполнить `!yolo detect predict`, указав источник данных в `source`. Результаты сохраняются в папке `runs/detect/predict`.\n",
        "\n",
        "Это все весьма интересно, однако понятно, что использовать модель в ноутбуке Google Colab большого практического смысла нет. Пришла пора забирать отсюда обученную модель, интегрировать ее в приложение или на сайт для решения важных практических задач.\n"
      ],
      "metadata": {
        "id": "EGiQw_gWbSBa"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7yrFRViVczX"
      },
      "source": [
        "#7.&nbsp;Deploy Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модели YOLO можно запускать на разлиных девайсах: PC, телефон, специальные автономные системы (Raspberry Pi, смарткамеры, беспилотники - часто, в условиях жесткого ограничения по ресурсам). Ultralytics позволяет конвертировать модель в другие форматы (`tflite`, `onnx`, etc.) для использования в различных средах.\n"
      ],
      "metadata": {
        "id": "FEtybPmB_ERi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.1 Download YOLO Model\n",
        "\n",
        "Здесь архивируем и сохраняем свой экземпляр модели.\n",
        "\n",
        "Запуск этого блока создает папку `my_model`, сохраняет в нее архив, в котором лежит версия `best.pt` (переименованная в `my_model.pt`) и дополительная информация о процессе обучения. Архив будет называться `my_model.zip`."
      ],
      "metadata": {
        "id": "IcoBAeHXa86W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create \"my_model\" folder to store model weights and train results\n",
        "!mkdir /content/my_model\n",
        "!cp /content/runs/detect/train/weights/best.pt /content/my_model/my_model.pt\n",
        "!cp -r /content/runs/detect/train /content/my_model\n",
        "\n",
        "# Zip into \"my_model.zip\"\n",
        "%cd my_model\n",
        "!zip /content/my_model.zip my_model.pt\n",
        "!zip -r /content/my_model.zip train\n",
        "%cd /content"
      ],
      "metadata": {
        "id": "qcBdnOA9v85S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43ypwonynLVu"
      },
      "outputs": [],
      "source": [
        "# Можно выполнить код, чтобы сохранить архив локально и просто пойти в сайдбар и скачать.\n",
        "from google.colab import files\n",
        "\n",
        "files.download('/content/my_model.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.2 Deploy YOLO Model on Local Devices\n",
        "\n",
        "На этом этапе мы заканчиваем работу в данном ноутбуке. Процесс деплоя модели в приложение для детекции объектов будет развернут в моем [репозитории](https://github.com/nboravlev/Trash_detection_with_YOLO/tree/main/App) на GitHub"
      ],
      "metadata": {
        "id": "YL06c6pb_UqZ"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}